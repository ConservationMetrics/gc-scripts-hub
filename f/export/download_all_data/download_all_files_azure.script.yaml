summary: 'Export: Generate commands for downloading all files from Azure Blob Storage'
description: >-
  This script generates a SAS URL for an Azure Blob Storage container or subfolder
  and provides multiple `azcopy` command options for different destinations:
  local disk, AWS S3, Google Cloud Storage, or another Azure Storage account.
  Ideal for creating fast and reliable file transfer options without requiring
  zipping large directories or putting load on your GC deployment.

lock: '!inline f/export/download_all_files_azure/download_all_files_azure.script.lock'
concurrency_time_window_s: 0
kind: script

schema:
  $schema: 'https://json-schema.org/draft/2020-12/schema'
  type: object
  order:
    - blob_connection_string
    - container_name
    - folder_path
    - expiry_minutes
  properties:
    blob_connection_string:
      type: string
      description: >-
        Azure Storage connection string for accessing the blob storage account.
        Format:
        "DefaultEndpointsProtocol=https;AccountName=youracct;AccountKey=yourkey;EndpointSuffix=core.windows.net"
      format: password
    container_name:
      type: string
      description: >-
        The name of the Azure Blob Storage container (e.g., "datalake").
        This should match one of the containers visible in the Azure portal.
      pattern: '^[a-z0-9\-]+$'
    folder_path:
      type: string
      description: >-
        Optional subfolder path within the container to restrict access.
        Leave blank to expose the entire container.
      default: ""
    expiry_minutes:
      type: integer
      description: >-
        How many minutes the generated SAS URL will remain valid.
      default: 120
  required:
    - blob_connection_string
    - container_name
